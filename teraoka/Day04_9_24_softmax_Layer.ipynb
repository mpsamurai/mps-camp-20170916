{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (2,1) doesn't match the broadcast shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-1df28a862743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mn1_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manser\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 1層目に2層目の重みV とdeltaを付けて実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn1_myself_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 2層目のパラメータの更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1層目のパラメータの更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-1df28a862743>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, input_x)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;34m\"\"\"パラメーター更新\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# 入力値(y10を与えている) # self._delta * input_x.T(W00,01,10,11の∂)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bias\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (2,1) doesn't match the broadcast shape (2,2)"
     ]
    }
   ],
   "source": [
    "# sotmax Layerを用いたNNモデル\n",
    "# 多層レイヤー（bitデータ(1を与えるとy20は1を返し、y21は反転を返す）\n",
    "import numpy as np\n",
    "class Layer:\n",
    "    \n",
    "    def __init__(self, m, n): \n",
    "        self._rate = 0.1\n",
    "        self._weight = np.random.rand(m, n) - 0.5  # m行n列を設定(-0.5をすることで-0.5 ~ 0.5の範囲にする)\n",
    "        self._bias = np.zeros((m, 1))  # m行1列の　0ベクトルを作成してくれている  # バイアスは出力の行\n",
    "        self._y = None\n",
    "        self._delta = None\n",
    "        self._identity = np.identity(m)\n",
    "        \n",
    "        \n",
    "    def set_state(self, x):\n",
    "        \"\"\"入力値を内積\"\"\"\n",
    "        s = (self._weight.dot(x))+1*self._bias\n",
    "        return s\n",
    "\n",
    "    def activate(self, s):\n",
    "        \"今回はシグモイド関数\"\n",
    "        self._y = 1 / (1 + np.exp(-s))\n",
    "        return self._y\n",
    "\n",
    "    def softmax(self, s):\n",
    "        self._y =  s * (self._identity.T - s)\n",
    "        return self._y\n",
    "                        \n",
    "    \n",
    "    def foward(self, x):\n",
    "        \"\"\"順伝播\"\"\"\n",
    "        return self.activate(self.set_state(x))\n",
    "    \n",
    "    def back_propagation(self, prev_W, prev_delta, t):\n",
    "        \"\"\"勾配計算(誤差逆伝播)\"\"\"\n",
    "        if prev_W is not None:\n",
    "            # deltaを持って入ればパラメータの伝播( ∂E/∂W , ∂E/∂b)\n",
    "            self._delta = prev_W.T.dot(prev_delta) * self._y  # (V00,01,10,11前回パラメータ) * (∂20,21前回delta) * (y10,y11今回出力)\n",
    "        else:\n",
    "            de = self._y - t\n",
    "            dy = self._y * (np.identity(len(self._y)) - self._y).T\n",
    "#             dy = self._y * (1 - self._y)  # シグモイドの偏微分\n",
    "            self._delta = de * dy  # 初回誤差(delta) \n",
    "        return self._delta\n",
    "    \n",
    "    \n",
    "    def update(self, input_x):\n",
    "        \"\"\"パラメーター更新\"\"\"\n",
    "        self._weight -= self._rate * self._delta * input_x.T  # 入力値(y10を与えている) # self._delta * input_x.T(W00,01,10,11の∂)\n",
    "        self._bias -= self._delta * self._bias\n",
    "        return self._y\n",
    "    \n",
    "    def error_function(self, y, o):\n",
    "        return (1/2 * np.power(y[0] - o[0],2)) + (1/2 * np.power(y[1] - o[1],2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bit_input = np.array([[[1.]],\n",
    "                          [[0.]],\n",
    "                          [[1.]],\n",
    "                          [[1.]],\n",
    "                          [[0.]]])\n",
    "    bit_output = np.array([[[1.],\n",
    "                            [0.]],\n",
    "                           [[0.],\n",
    "                            [1.]],\n",
    "                           [[1.],\n",
    "                            [0.]],\n",
    "                           [[1.],\n",
    "                            [0.]],\n",
    "                           [[0.],\n",
    "                            [1.]]])\n",
    "    \n",
    "    n1 = Layer(2,1) # １層目 ：(1入力)入力値が列、(2出力)出力値が行\n",
    "    n2 = Layer(2,2) # ２層目 ：(2入力)入力値が列、(2出力)出力値が行\n",
    "    prev_W = None\n",
    "    prev_delta = None\n",
    "    for _ in range(100):\n",
    "        for input_x, anser in zip(bit_input,bit_output):\n",
    "            n1_myself_y = n1.foward(input_x)  # 1層目に値実行\n",
    "            n2.foward(n1_myself_y)  # 2層目に値実行\n",
    "            n2.back_propagation(prev_W, prev_delta, anser)  # 2層目に前の重みV と 前のdeltaを付けて実行\n",
    "            prev_W, prev_delta = n2._weight, n2._delta  # 2層目の重みV と deltaを抜き出している(後に利用するため)\n",
    "            n1_delta = n1.back_propagation(prev_W, prev_delta, anser)  # 1層目に2層目の重みV とdeltaを付けて実行\n",
    "\n",
    "            n2.update(n1_myself_y) # 2層目のパラメータの更新\n",
    "            n1.update(input_x) # 1層目のパラメータの更新\n",
    "            \n",
    "            n1_myself_y = n1.foward(input_x) # 最終的な誤差を計算するために一度foward n1から\n",
    "            n2_myself_y = n2.softmax(n1_myself_y)  # n2は最後なのでsoftmaxへ\n",
    "            \n",
    "            print(\"誤差：\", n1.error_function(n2_myself_y, anser)) # n1.fowardから求められた予測値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
